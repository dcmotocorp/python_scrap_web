data_list = ['https://www.catch.com.au/shop/home-kitchen/arts-crafts-sewing', 'https://www.catch.com.au/shop/home-kitchen/kitchen', 'https://www.catch.com.au/shop/home-kitchen/festive-party-supplies', 'https://www.catch.com.au/shop/home-kitchen/stationery', 'https://www.catch.com.au/shop/home-kitchen/bathroom', 'https://www.catch.com.au/shop/home-kitchen/outdoor', 'https://www.catch.com.au/shop/home-kitchen/books-media', 'https://www.catch.com.au/shop/home-kitchen/home-storage', 'https://www.catch.com.au/shop/home-kitchen/rugs', 'https://www.catch.com.au/shop/home-kitchen/personalised', 'https://www.catch.com.au/shop/home-kitchen/dining', 'https://www.catch.com.au/shop/home-kitchen/tools-hardware', 'https://www.catch.com.au/shop/home-kitchen/diy', 'https://www.catch.com.au/shop/beauty/makeup', 'https://www.catch.com.au/shop/beauty/bath-body', 'https://www.catch.com.au/shop/beauty/mens-grooming', 'https://www.catch.com.au/shop/beauty/aromatherapy', 'https://www.catch.com.au/shop/beauty/skincare', 'https://www.catch.com.au/shop/beauty/fragrance', 'https://www.catch.com.au/shop/beauty/beauty-grooming', 'https://www.catch.com.au/shop/beauty/hair-care', 'https://www.catch.com.au/shop/beauty/toiletries', 'https://www.catch.com.au/shop/beauty/dental-oral-care', 'https://www.catch.com.au/shop/beauty/manicure-pedicure', 'https://www.catch.com.au/shop/grocery-liquor/snacks', 'https://www.catch.com.au/shop/grocery-liquor/international-foods', 'https://www.catch.com.au/shop/grocery-liquor/confectionery', 'https://www.catch.com.au/shop/grocery-liquor/beverage', 'https://www.catch.com.au/shop/grocery-liquor/home-car-cleaning', 'https://www.catch.com.au/shop/grocery-liquor/healthy-foods', 'https://www.catch.com.au/shop/grocery-liquor/breakfast', 'https://www.catch.com.au/shop/grocery-liquor/pantry-staples', 'https://www.catch.com.au/shop/grocery-liquor/baby-food', 'https://www.catch.com.au/shop/grocery-liquor/pets', 'https://www.catch.com.au/shop/grocery-liquor/liquor', 'https://www.catch.com.au/shop/grocery-liquor/vitamins-medicinal', 'https://www.catch.com.au/shop/grocery-liquor/toiletries', 'https://www.catch.com.au/shop/grocery-liquor/shop-all-pantry', 'https://www.catch.com.au/shop/pets/food-and-treats', 'https://www.catch.com.au/shop/pets/pet-medicine', 'https://www.catch.com.au/shop/pets/pet-accessories', 'https://www.catch.com.au/shop/pets/toys', 'https://www.catch.com.au/shop/pets/bedding', 'https://www.catch.com.au/shop/pets/kennels', 'https://www.catch.com.au/shop/pets/cat-scratchers', 'https://www.catch.com.au/shop/pets/carriers-cages', 'https://www.catch.com.au/shop/sports-outdoor/men', 'https://www.catch.com.au/shop/sports-outdoor/boys', 'https://www.catch.com.au/shop/sports-outdoor/bat-ball-sports-equipment', 'https://www.catch.com.au/shop/sports-outdoor/ball-sports-equipment', 'https://www.catch.com.au/shop/sports-outdoor/women', 'https://www.catch.com.au/shop/sports-outdoor/girls', 'https://www.catch.com.au/shop/sports-outdoor/racquet-sports-equipment', 'https://www.catch.com.au/shop/sports-outdoor/camping-hiking', 'https://www.catch.com.au/shop/sports-outdoor/accessories', 'https://www.catch.com.au/shop/sports-outdoor/health-wellbeing', 'https://www.catch.com.au/shop/sports-outdoor/gym-equipment', 'https://www.catch.com.au/shop/sports-outdoor/outdoor-sport-activities', 'https://www.catch.com.au/shop/toys-games/kids-toys-games', 'https://www.catch.com.au/shop/toys-games/books', 'https://www.catch.com.au/shop/toys-games/baby-toys-activities', 'https://www.catch.com.au/shop/toys-games/art-craft', 'https://www.catch.com.au/shop/toys-games/radio-control-toys', 'https://www.catch.com.au/shop/toys-games/costumes-novelty', 'https://www.catch.com.au/shop/kids-clothing-toys/girls-clothing', 'https://www.catch.com.au/shop/kids-clothing-toys/kids-accessories', 'https://www.catch.com.au/shop/kids-clothing-toys/kids-bedroom', 'https://www.catch.com.au/shop/kids-clothing-toys/boys-clothing', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-sleep-products', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-bedding', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-bath-products', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-feeding', 'https://www.catch.com.au/shop/kids-clothing-toys/nappies-on-sale', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-safety', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-clothing', 'https://www.catch.com.au/shop/kids-clothing-toys/baby-travel', 'https://www.catch.com.au/shop/kids-clothing-toys/personalised', 'https://www.catch.com.au/shop/furniture/dining-kitchen', 'https://www.catch.com.au/shop/furniture/storage-organisation', 'https://www.catch.com.au/shop/furniture/nursery-furniture', 'https://www.catch.com.au/shop/furniture/living-room', 'https://www.catch.com.au/shop/furniture/outdoor', 'https://www.catch.com.au/shop/furniture/rugs', 'https://www.catch.com.au/shop/furniture/bedroom', 'https://www.catch.com.au/shop/furniture/office', 'https://www.catch.com.au/shop/furniture/kids', 'https://www.catch.com.au/shop/appliances/cooking-dishwashers', 'https://www.catch.com.au/shop/appliances/vacuum-floorcare', 'https://www.catch.com.au/shop/appliances/coffee-machines-beverage', 'https://www.catch.com.au/shop/appliances/specialty-appliances', 'https://www.catch.com.au/shop/appliances/fridges-freezers', 'https://www.catch.com.au/shop/appliances/laundry', 'https://www.catch.com.au/shop/appliances/benchtop-cooking', 'https://www.catch.com.au/shop/appliances/healthcare', 'https://www.catch.com.au/shop/appliances/heating-cooling', 'https://www.catch.com.au/shop/appliances/toaster-kettle', 'https://www.catch.com.au/shop/appliances/mixers-food-processor', 'https://www.catch.com.au/shop/appliances/bathroom', 'https://www.catch.com.au/shop/electronics/audio-speakers', 'https://www.catch.com.au/shop/electronics/headphones', 'https://www.catch.com.au/shop/electronics/home-cinema-tv-video', 'https://www.catch.com.au/shop/electronics/car-electronics', 'https://www.catch.com.au/shop/electronics/computers-laptops', 'https://www.catch.com.au/shop/electronics/digital-storage', 'https://www.catch.com.au/shop/electronics/tablet-ereader', 'https://www.catch.com.au/shop/electronics/printers-scanners', 'https://www.catch.com.au/shop/electronics/cameras', 'https://www.catch.com.au/shop/electronics/drones', 'https://www.catch.com.au/shop/electronics/gaming', 'https://www.catch.com.au/shop/electronics/home-security', 'https://www.catch.com.au/shop/electronics/power', 'https://www.catch.com.au/shop/electronics/phones-smart-tech', 'https://www.catch.com.au/shop/electronics/music', 'https://www.catch.com.au/shop/electronics/catch-mobile']


co= ['https://www.catch.com.au/shop/home-kitchen/bedding', 'https://www.catch.com.au/shop/home-kitchen/home-decor', ]

import logging

from selenium import webdriver
from bs4 import BeautifulSoup
import csv
import time
import string
import random
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import json 
from selenium.webdriver.support.ui import WebDriverWait
from concurrent.futures import ThreadPoolExecutor, wait,ProcessPoolExecutor
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
import json
import os,time
from selenium.webdriver.common.action_chains import ActionChains
import ctypes
logging.getLogger('selenium').setLevel(logging.WARNING)
# Set maximum memory allocation to 4 GB
soft_limit = 4 * 1024 * 1024 * 1024  # 4 GB in bytes

# Get a handle to the current process
process_handle = ctypes.windll.kernel32.GetCurrentProcess()

# Set the maximum working set size
ctypes.windll.kernel32.SetProcessWorkingSetSizeEx(
    process_handle,
    ctypes.c_size_t(-1),
    ctypes.c_size_t(soft_limit),
    ctypes.c_uint(0)
)


threadss = ThreadPoolExecutor(max_workers=3)
processes = ProcessPoolExecutor(max_workers=2)

workers = 3
process_worker = 2
filename = "products.csv"

main_page_url = 'https://www.catch.com.au/shop'
domain_url = "https://www.catch.com.au"

url = 'https://www.catch.com.au/shop/home-kitchen/bedding'
base_url = "https://www.catch.com.au"


fields = ["ID","Type","SKU","Name","Published","Is featured?","Visibility in catalog","Short description","Description","Date sale price starts","Date sale price ends","Tax status","Tax class","In stock?","Stock","Low stock amount","Backorders allowed?","Sold individually?","Weight (kg)","Length (cm)","Width (cm)","Height (cm)","Allow customer reviews?","Purchase note","Sale price","Regular price","Categories","Tags","Shipping class","Images","Download limit","Download expiry days","Parent","Grouped products","Upsells","Cross-sells","External URL","Button text","Position","Swatches Attributes","Attribute 1 name","Attribute 1 value(s)","Attribute 1 visible","Attribute 1 global","Attribute 2 name","Attribute 2 value(s)","Attribute 2 visible","Attribute 2 global"]
  
#========================= get the random_id with Unique ==========================

import json, os 
import random

def write_list_to_file(filename, my_list):
    with open(filename, 'w') as file:
        json.dump(my_list, file)

def read_list_from_file(filename):
    with open(filename, 'r') as file:
        my_list = json.load(file)
        return my_list

def get_random_number():
    return random.randint(0,1000000000)

def check_number(generatre_id):
    if os.path.exists('ids.txt'):
        lists = read_list_from_file('ids.txt')
        if generatre_id not in lists:
            lists.append(generatre_id)
            write_list_to_file('ids.txt',lists) 
            return True,generatre_id
    
        else:
            return False,generatre_id


def get_random_id_generator():
    if os.path.exists('ids.txt'):
        generatre_id =   get_random_number() 
        status = False
        generatre_id = None
        status,generatre_id = check_number(generatre_id)
        while status ==False :
            
            generatre_id =   get_random_number() 
            status,generatre_id = check_number(generatre_id)
        return  generatre_id 
    else:
         
            lists = []
            lists.append(random.randint(0,100))
            write_list_to_file('ids.txt',lists)


def read_to_txt(file_name):
    with open(file_name, 'r') as txtfile:
        data = json.load(txtfile)
        return data


def get_sku_value():
    string_char = string.ascii_letters
    unique_str0 = random.choice(list(string_char))
    unique_str1 = random.choice(list(string_char))
    unique_str2 = random.choice(list(string_char))
    unique_str3 = random.choice(list(string_char))
    uniquw_number = random.randint(0000,9999)

    key = unique_str0+unique_str1+unique_str2+unique_str3+str(uniquw_number)
    return key

def write_to_csv(file_name,row):
    with open(file_name, 'a',newline='') as csvfile:
        csvwriter = csv.writer(csvfile)
        csvwriter.writerow(row)

def exxtra_prodyuct(name,price_value,product,category_name,file_name,ids):
    row = []
    start_time = time.time()
    try:
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-software-rasterizer")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-infobars")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-images")
        chrome_options.add_argument("--disable-javascript")
        chrome_options.add_argument("--disable-web-security")
        chrome_options.add_argument("--disable-features=AnimationWorklet")
        chrome_options.add_argument("--disable-features=CSSLayoutNG")
        chrome_options.add_argument("--ignore-certificate-errors")
        # chrome_options.add_argument("--disable-webgl")
        chrome_options.add_argument("--js-flags=--max-old-space-size=4096")
        chrome_options.add_argument('--blink-settings=imagesEnabled=false')
        chrome_options.page_load_strategy = 'eager'
        driver2 = webdriver.Chrome(options=chrome_options)  # Replace with the path
        timeout = 5
        driver2.implicitly_wait(timeout)
        # driver2.set_page_load_timeout(20)
        try:
            driver2.get(product)
            time.sleep(1)
        except WebDriverException as e:
            driver2.delete_all_cookies()
            driver2.execute_script("window.localStorage.clear()")
            driver2.execute_script("window.sessionStorage.clear()")
            driver2.execute_cdp_cmd("Network.clearBrowserCache", {})
            driver2.quit()
            time.sleep(2)
            exxtra_prodyuct(name,price_value,product,category_name,file_name,ids)
        # time.sleep(3) 
        print("product get info 0====================0.1waut",time.time()-start_time)
        html2 = driver2.page_source
        soup = BeautifulSoup(html2, 'html.parser')
        print("product get info 0==================== soap apr",time.time()-start_time)
        del html2
        data = soup.find('div', {'class': 'css-1q971by'})        
        discription_data = data.find('section', {'class': 'css-2w60ma'}) 
        dais = discription_data.find('div', {'class': 'css-1oteowz'})
        del discription_data
        data__ = soup.find('script', {'id': '__NEXT_DATA__'}).get_text()
        del soup
        data__ = json.loads(data__)
        galary =  data__['props']['pageProps']['data']['productById']['assets']['gallery']
        del data__,data
        image =  [_data.get('url') for _data in galary]
        del galary
        l2 = ",".join(image)
        del image
        colors=[]
        print("product get info 3====================",time.time()-start_time)
        try:
            button = driver2.find_element(By.XPATH, '//*[@id="maincontent"]/section/div[2]/div[2]/section[2]/div/div/div[2]/div/div/button')
            # button.click()
            print("=============================button",button)
            actions = ActionChains(driver2)
            actions.move_to_element(button).click().perform()            
            print("product get info 4====================",time.time()-start_time)
            dropdown = driver2.find_element(By.XPATH, '//*[@id="maincontent"]/section/div[2]/div[2]/section[2]/div/div/div[2]/div/div/ul')
            html3 = driver2.page_source
            driver2.delete_all_cookies()
            time.sleep(0.5)
            driver2.execute_script("window.localStorage.clear()")
            time.sleep(0.5)
            driver2.execute_script("window.sessionStorage.clear()")
            time.sleep(0.5)
            driver2.execute_cdp_cmd("Network.clearBrowserCache", {})
            time.sleep(0.5)
            driver2.quit()            
            soup4 = BeautifulSoup(html3, 'html.parser')
            print("product get info 5====================",time.time()-start_time)
            del html3
            test__ = soup4.find_all('ul', {'class': 'css-3p3bh0'})
            del soup4
            for test in test__:
                all_dest= test.findAll('li',{'class': 'css-r44k6v'})
                for test in all_dest:
                    x = test.find('span',{'class': 'css-h2vvlj ehnxcr60'}).get_text()
                    colors.append(x)
                    del test,x
                del all_dest
            print("product get info 6====================",time.time()-start_time)
            del test__            
            print("product get info 7====================",time.time()-start_time)
        except Exception as ex:
            try:
                try:
        
                    driver2.delete_all_cookies()
                except Exception as ex:
                    pass
                try:
                    driver2.execute_script("window.localStorage.clear()")           
                except WebDriverException as e:
                    print("==========failed to access")
                    pass
                
                try:
                    driver2.execute_script("window.sessionStorage.clear()")          
                except WebDriverException as e:
                    print("==========failed to access")
                    pass

                try:
                    driver2.execute_cdp_cmd("Network.clearBrowserCache", {})          
                except WebDriverException as e:
                    print("==========failed to access")
                    pass
                
                try:
                    driver2.quit()         
                except WebDriverException as e:
                    print("==========failed to access")
                    pass
            except Exception as ex:
                pass
            print("product get info exxxxxxxxxxxxxxx====================",time.time()-start_time)
            pass
         
        key_values = get_sku_value()
        sky_value = key_values
        print("product get info 8====================",time.time()-start_time)
        if colors and len(colors)>0:       
            row = [get_random_id_generator(),"variable",sky_value,name,1,0,"visible","",dais,"","",'taxable',"",1,"","",0,0,0,0,0,0,"","","",price_value,category_name,"","",l2,"","","","","","","","","","","size",','.join(colors),1,0,"","","",""]
            write_to_csv(file_name,row)
            
            for index,color in enumerate(colors):    
                Name_change = name+ '-'+color
                row = [get_random_id_generator(),"variation","",Name_change,1,0,"visible","","","","",'taxable',"parent",1,"","",0,0,0,0,0,0,"","","",price_value,"","","",l2,"","",sky_value,"","","","","","","","size",f"{color}","",0,"","","",""]
                write_to_csv(file_name,row)
        else:
            row = [get_random_id_generator(),"simple",get_sku_value(),name,1,0,"visible","",dais,"","",'taxable',"",1,"","",0,0,0,0,0,0,"","","",price_value,category_name,"","",l2,"","","","","","","","","","","","",1,0,"","","",""]                                
            write_to_csv(file_name,row)
    except Exception as ex:
        
        try:
            try:
        
                driver2.delete_all_cookies()
            except Exception as ex:
                pass
            try:
                driver2.execute_script("window.localStorage.clear()")           
            except WebDriverException as e:
                print("==========failed to access")
                pass
            
            try:
                driver2.execute_script("window.sessionStorage.clear()")          
            except WebDriverException as e:
                print("==========failed to access")
                pass

            try:
                driver2.execute_cdp_cmd("Network.clearBrowserCache", {})          
            except WebDriverException as e:
                print("==========failed to access")
                pass
            
            try:
                driver2.quit()         
            except WebDriverException as e:
                print("==========failed to access")
                pass
        except Exception as ex:
            pass 
        exxtra_prodyuct(name,price_value,product,category_name,file_name,ids)


def get_all_products_from_url(category_name,url,file_name):
    file_name__ = file_name.split('.')
    read_file_name = file_name__[0]+".txt"
    products = read_to_txt(read_file_name)
    row_list = []
    count = 0
    futires = []
    for name,price_value,product in products:
        ids = get_random_id_generator()
        # exxtra_prodyuct(name,price_value,product,category_name,file_name,ids)
        futires.append(threadss.submit(exxtra_prodyuct,name,price_value,product,category_name,file_name,ids))      
        if len(futires) >= workers:
            _ = wait(futires)
            futires = []
            print("=============process end0")    
            print("===process end")
        time.sleep(2)
                
        
#--------------------- End ALL Products details BY CATEGORIES --------------------#

def test(sub_category_link):
    category_info = sub_category_link.split('/')
    category_name =   category_info[-2] +">"+ category_info[-1]  
    file_name = category_info[-2] +"_"+ category_info[-1]+".csv"
    txt_file = category_info[-2] +"_"+ category_info[-1]+".txt"
    if os.path.exists(txt_file):
        if not os.path.exists(file_name):
            with open(file_name, 'a',newline='') as csvfile:
                csvwriter = csv.writer(csvfile) 
                csvwriter.writerow(fields)
            get_all_products_from_url(category_name,sub_category_link,file_name)

list_tem = []
lists = []
if os.path.isfile('ids.txt'):
    pass 
else:
    lists.append(get_random_number())
    write_list_to_file('ids.txt',lists)


if __name__ == '__main__':
    futires_process = []    
    for index,sub_category_link in enumerate(data_list):
        test(sub_category_link)  
        print("===process end")
        
        time.sleep(2)

